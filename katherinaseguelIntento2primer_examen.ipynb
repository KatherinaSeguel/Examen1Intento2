{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "qvJqMD29cm0b",
        "outputId": "24ed7879-23be-43bd-8617-8d5f27f0c188"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/hotel_bookings.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-862013575.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Cargar el archivo CSV en un DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#df = pd.read_csv(\"C:\\Users\\Kathy\\Downloads\\Analisis de datos con Pandas (Core)\\vgsales.csv\")  # Asegúrate de que el archivo esté en el mismo directorio que tu script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/hotel_bookings.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Mostrar las primeras 10 filas del DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/hotel_bookings.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Cargar el archivo CSV en un DataFrame\n",
        "#df = pd.read_csv(\"C:\\Users\\Kathy\\Downloads\\Analisis de datos con Pandas (Core)\\vgsales.csv\")\n",
        "df = pd.read_csv(\"C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/hotel_bookings.csv\")\n",
        "\n",
        "# Mostrar las primeras 10 filas del DataFrame\n",
        "print(df.head(10))\n",
        "\n",
        "\n",
        "\n",
        "# Muestra los duplicados antes\n",
        "print(\"Duplicados que se encontraron:\", df.duplicated().sum())\n",
        "\n",
        "# Elimina los registros duplicados\n",
        "df_limpio = df.drop_duplicates()\n",
        "\n",
        "# Muestra la cantidad de filas después de limpiar\n",
        "print(\"Filas después de eliminar duplicados:\", len(df_limpio))\n",
        "\n",
        "# Guardar el archivo limpio datos_limpios.csv\n",
        "df_limpio.to_csv(\"C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/datos_limpios.csv\", index=False)\n",
        "\n",
        "print(\"Archivo limpio guardado como 'datos_limpios.csv'\")\n",
        "\n",
        "#df = pd.read_csv(\"C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/datos_limpios.csv\",encoding=\"utf-8\")\n",
        "\n",
        "# Imprimir columnas\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Verificar tipos actuales\n",
        "print(\"Tipos de datos actuales:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "\n",
        "# Ajustar tipos de datos según diccionario manual\n",
        "\n",
        "df[\"Customer Name\"] = df[\"Customer Name\"].astype(str)\n",
        "df[\"Age\"] = pd.to_numeric(df[\"Age\"], errors=\"coerce\").astype(\"Int64\")\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
        "df[\"Product Category\"] = df[\"Product Category\"].astype(str)\n",
        "df[\"Price per Unit\"] = pd.to_numeric(df[\"Price per Unit\"], errors=\"coerce\")\n",
        "df[\"Quantity\"] = pd.to_numeric(df[\"Quantity\"], errors=\"coerce\").astype(\"Int64\")\n",
        "df[\"Total Amount\"] = pd.to_numeric(df[\"Total Amount\"], errors=\"coerce\")\n",
        "\n",
        "# Confirmar ajustes\n",
        "print(\"\\nTipos de datos después del ajuste:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Guardar el archivo corregido\n",
        "df.to_csv('C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/datos_con_tipos_ajustados.csv', index=False)\n",
        "\n",
        "print(\"\\nArchivo creado 'datos_con_tipos_ajustados.csv' corregidos.\")\n",
        "\n",
        "\n",
        "\n",
        "#  1: Identificar columnas categóricas\n",
        "columnas_categoricas = df.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "#  2: Normalizar los valores (eliminar espacios y poner en minúsculas)\n",
        "for col in columnas_categoricas:\n",
        "    df[col] = df[col].str.strip().str.lower()\n",
        "\n",
        "# 3: Imprimir valores únicos por columna para inspección\n",
        "print(\"\\nValores categóricos únicos por columna (normalizados):\")\n",
        "for col in columnas_categoricas:\n",
        "    print(f\"{col}: {df[col].unique()}\")\n",
        "\n",
        "# 4 (opcional): Reemplazar valores específicos según un diccionario\n",
        "# Por ejemplo, para una columna que contiene 'yes', 'Yes', 'YES', podrías estandarizar a 'Sí'\n",
        "reemplazos = {\n",
        "    \"yes\": \"sí\",\n",
        "    \"no\": \"no\",\n",
        "    \"n/a\": \"desconocido\",\n",
        "    \"\": \"desconocido\"\n",
        "}\n",
        "\n",
        "# Aplicar reemplazos a todas las columnas categóricas\n",
        "for col in columnas_categoricas:\n",
        "    df[col] = df[col].replace(reemplazos)\n",
        "\n",
        "# Guardar el archivo corregido\n",
        "df.to_csv('C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/datos_categoricos_normalizados.csv', index=False)\n",
        "\n",
        "print(\"\\n Consistencia de valores categóricos corregida. Archivo guardado como 'datos_categoricos_normalizados.csv'\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "df = pd.read_csv(\"C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/datos_categoricos_normalizados.csv\")\n",
        "\n",
        "# Mostrar resumen de valores faltantes\n",
        "print(\"Valores faltantes por columna:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Separar por tipo de dato\n",
        "columnas_numericas = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "columnas_categoricas = df.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "# Rellenar columnas numéricas con la mediana\n",
        "for col in columnas_numericas:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        mediana = df[col].median()\n",
        "        df[col].fillna(mediana, inplace=True)\n",
        "        print(f\"✔️ Columna numérica '{col}' rellenada con la mediana ({mediana})\")\n",
        "\n",
        "# Rellenar columnas categóricas con la moda\n",
        "for col in columnas_categoricas:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        moda = df[col].mode()[0]\n",
        "        df[col].fillna(moda, inplace=True)\n",
        "        print(f\"✔️ Columna categórica '{col}' rellenada con la moda ('{moda}')\")\n",
        "\n",
        "# Confirmación final\n",
        "print(\"\\n Valores faltantes corregidos.\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Guardar el nuevo archivo\n",
        "df.to_csv(\"C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/datos_sin_nulos.csv\", index=False)\n",
        "print(\"\\n  Archivo guardado como 'datos_sin_nulos.csv'\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Cargar el dataset\n",
        "df = pd.read_csv(\"C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/datos_sin_nulos.csv\")\n",
        "\n",
        "# Selecciona columnas numéricas para análisis\n",
        "columnas_numericas = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "\n",
        "# Identificar outliers usando el método del rango intercuartil (IQR)\n",
        "for col in columnas_numericas:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    limite_inferior = Q1 - 1.5 * IQR\n",
        "    limite_superior = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Contar valores atípicos\n",
        "    outliers = df[(df[col] < limite_inferior) | (df[col] > limite_superior)]\n",
        "    print(f\"'{col}': {len(outliers)} valores atípicos detectados\")\n",
        "\n",
        "    # Opcional: puedes eliminar o reemplazar los outliers\n",
        "    # Aquí los reemplazaremos por NaN para tratarlos luego si deseas\n",
        "    df.loc[(df[col] < limite_inferior) | (df[col] > limite_superior), col] = None\n",
        "\n",
        "# Guardar archivo con outliers neutralizados\n",
        "df.to_csv(\"C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/datos_sin_outliers.csv\", index=False)\n",
        "print(\"\\n  Archivo guardado como 'datos_sin_outliers.csv' con valores atípicos identificados.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Cargar el dataset limpio\n",
        "df = pd.read_csv(\"C:/Users/Kathy/Desktop/KatherinaSeguelExamen1Intento2/datos_sin_outliers.csv\")\n",
        "\n",
        "# 1️) Histograma: distribución de edad de los clientes\n",
        "plt.hist(df[\"Age\"], bins=10, color='skyblue', edgecolor='black')\n",
        "plt.title(\"Distribución de Edad de Clientes\")\n",
        "plt.xlabel(\"Edad\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Interpretación:\n",
        "# Este histograma muestra cómo se distribuyen las edades en el conjunto de datos.\n",
        "# Si hay una mayor concentración en cierto rango (por ejemplo, 30-40 años),\n",
        "# puede sugerir el segmento demográfico más activo en compras.\n",
        "\n",
        "# 2) Gráfico de barras: frecuencia por categoría de producto\n",
        "conteo_productos = df[\"Product Category\"].value_counts()\n",
        "conteo_productos.plot(kind='bar', color='orange', edgecolor='black')\n",
        "plt.title(\"Frecuencia por Categoría de Producto\")\n",
        "plt.xlabel(\"Categoría de Producto\")\n",
        "plt.ylabel(\"Número de Registros\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Interpretación:\n",
        "# Este gráfico de barras revela qué categorías de productos son las más frecuentes.\n",
        "# Una categoría dominante puede indicar alta rotación o popularidad.\n",
        "\n",
        "##Estas visualizaciones te permitirán detectar patrones básicos y sesgos en los datos antes de realizar análisis más complejos.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 1️) Gráfico de dispersión: relación entre Edad y Monto Total, según Categoría de Producto\n",
        "colors = {\"ropa\": \"skyblue\", \"tecnología\": \"orange\", \"hogar\": \"green\"}\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "for categoria in df[\"Product Category\"].unique():\n",
        "    subset = df[df[\"Product Category\"] == categoria]\n",
        "    plt.scatter(subset[\"Age\"], subset[\"Total Amount\"], label=categoria, alpha=0.6, color=colors.get(categoria, \"gray\"))\n",
        "\n",
        "plt.title(\"Relación entre Edad y Monto Total por Categoría de Producto\")\n",
        "plt.xlabel(\"Edad del Cliente\")\n",
        "plt.ylabel(\"Monto Total de la Compra\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Interpretación:\n",
        "# Este gráfico muestra cómo se distribuyen los montos de compra según la edad del cliente,\n",
        "# diferenciando por tipo de producto. Puede revelar si ciertos grupos de edad compran más\n",
        "# ciertos tipos de productos o gastan más.\n",
        "df[\"Customer Age Group\"] = pd.cut(df[\"Age\"],\n",
        "                                   bins=[0, 25, 40, 60, 100],\n",
        "                                   labels=[\"Joven\", \"Adulto Joven\", \"Adulto\", \"Senior\"])\n",
        "\n",
        "# 2️) Gráfico de barras agrupadas: promedio de monto por grupo de edad y categoría de producto\n",
        "agrupado = df.groupby([\"Customer Age Group\", \"Product Category\"])[\"Total Amount\"].mean().unstack()\n",
        "\n",
        "agrupado.plot(kind='bar', figsize=(8,5))\n",
        "plt.title(\"Promedio de Monto por Grupo de Edad y Categoría de Producto\")\n",
        "plt.xlabel(\"Grupo de Edad\")\n",
        "plt.ylabel(\"Monto Promedio\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Interpretación:\n",
        "# Este gráfico ayuda a comparar cuánto gastan en promedio los distintos grupos de edad\n",
        "# en cada categoría de producto. Es útil para definir estrategias de segmentación.\n",
        "\n",
        "#Estas visualizaciones te ofrecen perspectivas clave sobre comportamientos de gasto cruzados entre variables, como edad, monto y tipo de producto.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Seleccionar variables numéricas\n",
        "numericas = df.select_dtypes(include=[\"int64\", \"float64\"])\n",
        "\n",
        "# Resumen estadístico estándar\n",
        "resumen = numericas.describe().T  # Transponer para mejor visualización\n",
        "resumen[\"mediana\"] = numericas.median()\n",
        "resumen[\"rango_intercuartil\"] = resumen[\"75%\"] - resumen[\"25%\"]\n",
        "\n",
        "# Mostrar el resumen\n",
        "print(\"\\n Estadísticas descriptivas:\")\n",
        "print(resumen[[\"count\", \"mean\", \"mediana\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"rango_intercuartil\"]])\n",
        "\n"
      ]
    }
  ]
}